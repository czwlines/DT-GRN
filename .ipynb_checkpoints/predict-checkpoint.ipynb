{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from model import Model, MaskLoss\n",
    "from train_10f import load_data\n",
    "from data_utils import parseDataFea, parseA2\n",
    "from model import calculate_pearsonr, calculate_spearmanr, calculate_r2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def calculate_mse(ipt, tar, mask):\n",
    "    a, b = [], []\n",
    "    for i, k in torch.nonzero(mask):\n",
    "        a.append(ipt[i, k])\n",
    "        b.append(tar[i, k])\n",
    "    a = torch.Tensor(a)\n",
    "    b = torch.Tensor(b)\n",
    "    return mean_squared_error(a, b)\n",
    "\n",
    "from sklearn import metrics\n",
    "def calculate_auc(ipt, tar, mask):\n",
    "    a, b = [], []\n",
    "    for i, k in torch.nonzero(mask):\n",
    "        a.append(ipt[i, k])\n",
    "        b.append(tar[i, k])\n",
    "    a = torch.Tensor(a)\n",
    "    b = torch.Tensor(b)\n",
    "    return metrics.roc_auc_score(a, b)\n",
    "\n",
    "def calculate_acc(ipt, tar, mask):\n",
    "    a, b = [], []\n",
    "    for i, k in torch.nonzero(mask):\n",
    "        a.append(ipt[i, k])\n",
    "        b.append(tar[i, k])\n",
    "    a = torch.Tensor(a)\n",
    "    b = torch.Tensor(b)\n",
    "    return metrics.accuracy_score(a, b)\n",
    "\n",
    "def calculate_aupr(ipt, tar, mask):\n",
    "    a, b = [], []\n",
    "    for i, k in torch.nonzero(mask):\n",
    "        a.append(ipt[i, k])\n",
    "        b.append(tar[i, k])\n",
    "    a = torch.Tensor(a)\n",
    "    b = torch.Tensor(b)\n",
    "    p, r, *_ = metrics.precision_recall_curve(a, b)\n",
    "    return metrics.auc(r, p)\n",
    "\n",
    "def calculate_kappa(ipt, tar, mask):\n",
    "    a, b = [], []\n",
    "    for i, k in torch.nonzero(mask):\n",
    "        a.append(ipt[i, k])\n",
    "        b.append(tar[i, k])\n",
    "    a = torch.Tensor(a)\n",
    "    b = torch.Tensor(b)\n",
    "    return metrics.cohen_kappa_score(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ckp(ckp_file):\n",
    "    cur_fold = int(ckp_file.split('-')[-1][0])\n",
    "    checkpoint = torch.load(ckp_file)\n",
    "    args = checkpoint['args']\n",
    "    emb, A, target, mask = load_data('./data/', args.data_set, args.th_rate, args.edge_mask, 10, cur_fold)\n",
    "    dru_emb, dis_emb, tar_emb = emb\n",
    "    dru_dru_A, dis_dis_A, tar_tar_A, dru_dis_A, dru_tar_A = A\n",
    "    train_target, valid_target = target\n",
    "    train_mask, valid_mask = mask\n",
    "    device = args.device\n",
    "    dru_emb = dru_emb.to(device)\n",
    "    dis_emb = dis_emb.to(device)\n",
    "    tar_emb = tar_emb.to(device)\n",
    "    dru_dru_A = dru_dru_A.to(device)\n",
    "    dis_dis_A = dis_dis_A.to(device)\n",
    "    tar_tar_A = tar_tar_A.to(device)\n",
    "    dru_dis_A = dru_dis_A.to(device)\n",
    "    dru_tar_A = dru_tar_A.to(device)\n",
    "    \n",
    "    train_target = train_target.to(device)\n",
    "    valid_target = valid_target.to(device)\n",
    "\n",
    "    train_mask = train_mask.to(device)\n",
    "    valid_mask = valid_mask.to(device)\n",
    "\n",
    "    model = Model(\n",
    "        dru_emb=len(dru_emb[0]),\n",
    "        dis_emb=len(dis_emb[0]),\n",
    "        tar_emb=len(tar_emb[0]),\n",
    "        dru_hid=args.dru_hid_size,\n",
    "        dis_hid=args.dis_hid_size,\n",
    "        tar_hid=args.tar_hid_size,\n",
    "        edge_dim=args.edge_dim,\n",
    "        g_hid=args.g_hid,\n",
    "        layer=args.layer,\n",
    "        dp=args.dp,\n",
    "        decoder=args.decoder,\n",
    "        dru_agg=args.dru_agg,\n",
    "        device=args.device\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(dru_emb, dis_emb, tar_emb, dru_dru_A, dis_dis_A, tar_tar_A, dru_dis_A, dru_tar_A, valid_mask)\n",
    "\n",
    "        loss = calculate_mse(pred, valid_target, valid_mask)\n",
    "        pear = calculate_pearsonr(pred, valid_target, valid_mask)\n",
    "        spea = calculate_spearmanr(pred, valid_target, valid_mask)\n",
    "        r2sc = calculate_r2score(pred, valid_target, valid_mask)\n",
    "    \n",
    "    return [loss.item(), pear, spea, r2sc, valid_mask.cpu(), valid_target.cpu(), pred.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "matchmaker_cell_line = pickle.load(open('./data/cell_line_vec_dict.pt', 'rb'))\n",
    "exists_cell_line = os.listdir('./data/')\n",
    "cell_line = [name for name in matchmaker_cell_line if name in exists_cell_line]\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "data_all_score = defaultdict(lambda: [])\n",
    "ckp_list = [item for item in os.listdir('./result/')]\n",
    "ckp_list = sorted([['./result/' + item, item[12:], item[12:].split('_[')[0]] for item in ckp_list], key=lambda x:x[1])\n",
    "ckp_list, ckp_name_list = [], []\n",
    "for ckp in ckp_list:\n",
    "    if ckp[1] not in ckp_name_list:\n",
    "        ckp_list.append(ckp)\n",
    "        ckp_name_list.append(ckp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list = {}\n",
    "with open('res-grn-1201.pkl', 'rb') as f:\n",
    "    save_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_res_list = []\n",
    "for ckp in tqdm(ckp_list):\n",
    "    if ckp[0] in save_list:\n",
    "        continue\n",
    "    res = evaluate_ckp(ckp_file=ckp[0])\n",
    "    ckp_res_list.append(ckp + [res])\n",
    "    save_list[ckp[0]] = ckp + [res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsave_list = {save_list[ckp][1]: save_list[ckp] for ckp in save_list}\n",
    "ckp_res_list = []\n",
    "for ckp in tqdm(ckp_list):\n",
    "    assert ckp[1] in nsave_list\n",
    "    res = evaluate_ckp(ckp_file=ckp[0])\n",
    "    ckp_res_list.append(ckp + [res])\n",
    "    nsave_list[ckp[1]] = ckp + [res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_res_list = [nsave_list[ckp[1]] for ckp in ckp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_v2 import parseA, parseA2, parseDataFea\n",
    "def norm_deno(ckp_file):\n",
    "    checkpoint = torch.load(ckp_file)\n",
    "    args = checkpoint['args']\n",
    "    dru_dict, *_ = parseDataFea('drugfeature1_finger_extract.csv', path='./data/' + args.data_set + '/')\n",
    "    dru_dru_mat = parseA('drugdrug_extract.csv', dru_dict, path='./data/' + args.data_set + '/')\n",
    "    deno = dru_dru_mat.max() - dru_dru_mat.min()\n",
    "    return deno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deno_dict = {}\n",
    "error_dict = []\n",
    "res = defaultdict(lambda: {})\n",
    "for threshold in [0, 5, 10][::-1]:\n",
    "    for item in tqdm(ckp_res_list):\n",
    "        if item[0] in res[threshold]:\n",
    "            continue\n",
    "        if item[2] not in deno_dict:\n",
    "            deno_dict[item[2]] = norm_deno(item[0])\n",
    "        deno = deno_dict[item[2]]\n",
    "        ipt, tar, mask = item[-1][-1], item[-1][-2], item[-1][-3]\n",
    "        ipt = ipt * deno\n",
    "        tar = tar * deno\n",
    "        ipt = ipt >= threshold\n",
    "        tar = tar >= threshold\n",
    "        \n",
    "        try:\n",
    "            acc = calculate_acc(ipt, tar, mask)\n",
    "            auc = calculate_auc(ipt, tar, mask)\n",
    "            aupr = calculate_aupr(ipt, tar, mask)\n",
    "            kappa = calculate_kappa(ipt, tar, mask)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(item[1])\n",
    "            print(tar.max())\n",
    "            print(deno)\n",
    "            print(tar.max() * deno)\n",
    "            print(e.args)\n",
    "            raise e\n",
    "\n",
    "        res[threshold][item[0]] = [\n",
    "            item[0],\n",
    "            item[1],\n",
    "            item[2],\n",
    "            [acc, auc, aupr, kappa]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nres = defaultdict(lambda: defaultdict(lambda: []))\n",
    "for threshold in [0, 5, 10]:\n",
    "    for item in ckp_res_list:\n",
    "        nres[threshold][item[2]].append(res[threshold][item[0]])\n",
    "\n",
    "def mean(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "res_score = {}\n",
    "for threshold in [0, 5, 10]:\n",
    "    res_score[threshold] = defaultdict(lambda: [])\n",
    "    for key in nres[threshold]:\n",
    "        scores = [item[-1] for item in nres[threshold][key]]\n",
    "        res_score[threshold][key] = [mean(item) for item in zip(*scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res-grn-th=0.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(res_score[0]), f)\n",
    "\n",
    "with open('res-grn-th=5.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(res_score[5]), f)\n",
    "\n",
    "with open('res-grn-th=10.pkl', 'wb') as f:\n",
    "    pickle.dump(dict(res_score[10]), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
